{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "translation_using_transformer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Language translation using transformer\n",
        "\n",
        "We use a transformer architecture to build a German-to-English translator.\n",
        "\n",
        "For details, see:\n",
        "[Attention is all you need](https://papers.nips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf) and [The annotated transformer.](https://nlp.seas.harvard.edu/2018/04/03/attention.html#positional-encoding)"
      ],
      "metadata": {
        "id": "wPF1Bj6zVPFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download de_core_news_sm\n",
        "\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "import math\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torchtext\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import vocab\n",
        "from torchtext.vocab.vocab import Vocab\n",
        "from torchtext.utils import download_from_url, extract_archive\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn import (TransformerEncoder, \n",
        "                      TransformerDecoder,\n",
        "                      TransformerEncoderLayer, \n",
        "                      TransformerDecoderLayer)\n",
        "\n",
        "import io\n",
        "import time\n",
        "\n",
        "torch.manual_seed(0)\n",
        "torch.use_deterministic_algorithms(False)"
      ],
      "metadata": {
        "id": "iEksR6fkNL57"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data processing\n",
        "\n",
        "We load data, tokenize the raw sentences, build vocabularies for English and German, map sequence of tokens to tensors."
      ],
      "metadata": {
        "id": "WTLpInx6nNHl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhkrPitlM9ym",
        "outputId": "8fd87d98-e222-413a-a7a1-7eb12896bf0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 637k/637k [00:00<00:00, 74.9MB/s]\n",
            "100%|██████████| 569k/569k [00:00<00:00, 89.6MB/s]\n",
            "100%|██████████| 24.7k/24.7k [00:00<00:00, 12.9MB/s]\n",
            "100%|██████████| 21.6k/21.6k [00:00<00:00, 6.10MB/s]\n",
            "100%|██████████| 22.9k/22.9k [00:00<00:00, 17.5MB/s]\n",
            "100%|██████████| 21.1k/21.1k [00:00<00:00, 5.69MB/s]\n"
          ]
        }
      ],
      "source": [
        "# download and extract data\n",
        "url_base = 'https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/'\n",
        "train_urls = ('train.de.gz', 'train.en.gz')\n",
        "val_urls = ('val.de.gz', 'val.en.gz')\n",
        "test_urls = ('test_2016_flickr.de.gz', 'test_2016_flickr.en.gz')\n",
        "\n",
        "train_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in train_urls]\n",
        "val_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in val_urls]\n",
        "test_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in test_urls]\n",
        "\n",
        "# get tokenizers, english and german\n",
        "de_tokenizer = get_tokenizer('spacy', language='de_core_news_sm')\n",
        "en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "\n",
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "\n",
        "def build_vocab(filepath: str, tokenizer) -> Vocab:\n",
        "    \"\"\"\n",
        "    Build and return vocabulary object.\n",
        "    \"\"\"\n",
        "    # ordered dictionary: tokens -> frequencies\n",
        "    counter = Counter()\n",
        "    with io.open(filepath, encoding=\"utf8\") as f:\n",
        "        for string_ in f:\n",
        "            counter.update(tokenizer(string_))\n",
        "    vocab_ = vocab(counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
        "    vocab_.set_default_index(UNK_IDX)\n",
        "    return vocab_\n",
        "\n",
        "de_vocab = build_vocab(train_filepaths[0], de_tokenizer)\n",
        "en_vocab = build_vocab(train_filepaths[1], en_tokenizer)\n",
        "\n",
        "def data_process(filepaths: List[str]) -> List[Tuple[Tensor, Tensor]]:\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        filepaths: list with file paths to german and english language data.\n",
        "    Returns:\n",
        "        data: List of data samples. Each sample is a tuple containing the\n",
        "            english and german versions of the sentence. \n",
        "    \"\"\"\n",
        "    raw_de_iter = iter(io.open(filepaths[0], encoding=\"utf8\"))\n",
        "    raw_en_iter = iter(io.open(filepaths[1], encoding=\"utf8\"))\n",
        "    data = []\n",
        "    for (raw_de, raw_en) in zip(raw_de_iter, raw_en_iter):\n",
        "        # tokenize sentence, map tokens to indeces\n",
        "        de_tensor_ = torch.tensor([de_vocab[token] for token in de_tokenizer(raw_de.rstrip(\"\\n\"))],\n",
        "                            dtype=torch.long)\n",
        "        en_tensor_ = torch.tensor([en_vocab[token] for token in en_tokenizer(raw_en.rstrip(\"\\n\"))],\n",
        "                            dtype=torch.long)\n",
        "        data.append((de_tensor_, en_tensor_))\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "def generate_batch(data_batch):\n",
        "    \"\"\"\n",
        "    Adds beginning/end of sentence markers, and pads. Collate function\n",
        "    for dataloaders.\n",
        "    \"\"\"\n",
        "    de_batch, en_batch = [], []\n",
        "    for (de_item, en_item) in data_batch:\n",
        "        # append BOS and EOS indeces\n",
        "        de_batch.append(torch.cat([torch.tensor([BOS_IDX]), de_item, torch.tensor([EOS_IDX])], dim=0))\n",
        "        en_batch.append(torch.cat([torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0))\n",
        "    # pad so all sequences in the batch have same length\n",
        "    de_batch = pad_sequence(de_batch, padding_value=PAD_IDX)\n",
        "    en_batch = pad_sequence(en_batch, padding_value=PAD_IDX)\n",
        "\n",
        "    return de_batch, en_batch\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# datasets\n",
        "train_data = data_process(train_filepaths)\n",
        "val_data = data_process(val_filepaths)\n",
        "test_data = data_process(test_filepaths)\n",
        "\n",
        "# dataloaders\n",
        "train_iter = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
        "                        shuffle=True, collate_fn=generate_batch)\n",
        "valid_iter = DataLoader(val_data, batch_size=BATCH_SIZE,\n",
        "                        shuffle=True, collate_fn=generate_batch)\n",
        "test_iter = DataLoader(test_data, batch_size=BATCH_SIZE,\n",
        "                       shuffle=True, collate_fn=generate_batch)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(' '.join(de_vocab.lookup_tokens(train_data[0][0].tolist())))\n",
        "print(' '.join(en_vocab.lookup_tokens(train_data[0][1].tolist())))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyE4eLD2OUwx",
        "outputId": "d6c19dd2-a07a-48ca-db17-3aae1f02adf4"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche .\n",
            "Two young , White males are outside near many bushes .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Architecture "
      ],
      "metadata": {
        "id": "50b7c-qerfDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NHEAD = 8 # the number of heads in the multiheadattention models\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Computes positional encoding. The positional encoding is added to the token \n",
        "    embedding to introduce a notion of word order\n",
        "\n",
        "    Args:\n",
        "        emb_size: embedding dimension. The positional encodings have the same \n",
        "            dimension as the embeddings so that the two can be summed\n",
        "    \"\"\"\n",
        "    def __init__(self, emb_size: int, dropout, maxlen: int = 5000):\n",
        "        super().__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2) * math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        return self.dropout(token_embedding +\n",
        "                            self.pos_embedding[:token_embedding.size(0),:])\n",
        "\n",
        "class TokenEmbedding(nn.Module):\n",
        "    \"\"\"\n",
        "    Embeds index tensors to dense semantic represantion.\n",
        "    \n",
        "    Args:\n",
        "        vocab_size: size of vocabulary.\n",
        "        emb_size: embedding space dimension.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size: int, emb_size) -> None:\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: Tensor) -> Tensor:\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
        "\n",
        "\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    \"\"\"\n",
        "    Sequence-to-sequence translation architecture.\n",
        "\n",
        "    num_encoder_layers: the number of sub-encoder-layers in the encoder.\n",
        "    num_decoder_layers: the number of sub-decoder-layers in the decoder.\n",
        "    emb_size: the number of expected dimensionality in the input (embedded).\n",
        "    \"\"\"\n",
        "    def __init__(self, \n",
        "                 num_encoder_layers: int, \n",
        "                 num_decoder_layers: int,\n",
        "                 emb_size: int, \n",
        "                 src_vocab_size: int, \n",
        "                 tgt_vocab_size: int,\n",
        "                 dim_feedforward:int = 512, \n",
        "                 dropout:float = 0.1\n",
        "                 ) -> None:\n",
        "\n",
        "        super().__init__()\n",
        "        encoder_layer = TransformerEncoderLayer(d_model=emb_size, \n",
        "                                                nhead=NHEAD,\n",
        "                                                dim_feedforward=dim_feedforward\n",
        "                                                )\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layer, \n",
        "                                                      num_layers=num_encoder_layers)\n",
        "        decoder_layer = TransformerDecoderLayer(d_model=emb_size, \n",
        "                                                nhead=NHEAD,\n",
        "                                                dim_feedforward=dim_feedforward)\n",
        "        self.transformer_decoder = TransformerDecoder(decoder_layer, \n",
        "                                                      num_layers=num_decoder_layers)\n",
        "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
        "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
        "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
        "        self.positional_encoding = PositionalEncoding(emb_size, dropout=dropout)\n",
        "\n",
        "    def forward(self, \n",
        "                src: Tensor, \n",
        "                trg: Tensor, \n",
        "                src_mask: Tensor,\n",
        "                tgt_mask: Tensor, \n",
        "                src_padding_mask: Tensor,\n",
        "                tgt_padding_mask: Tensor, \n",
        "                memory_key_padding_mask: Tensor):\n",
        "        \n",
        "        # embed and positional encode, source and target\n",
        "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
        "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "        # encoder pass for the source\n",
        "        memory = self.transformer_encoder(src_emb, \n",
        "                                          src_mask, \n",
        "                                          src_padding_mask)\n",
        "        # decoder using memory and target\n",
        "        outs = self.transformer_decoder(tgt_emb, memory, tgt_mask, \n",
        "                                        memory_mask=None,\n",
        "                                        tgt_key_padding_mask=tgt_padding_mask, \n",
        "                                        memory_key_padding_mask=memory_key_padding_mask)\n",
        "        return self.generator(outs)\n",
        "\n",
        "    def encode(self, src: Tensor, src_mask: Tensor):\n",
        "        return self.transformer_encoder(self.positional_encoding(\n",
        "                            self.src_tok_emb(src)), src_mask)\n",
        "\n",
        "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
        "        return self.transformer_decoder(self.positional_encoding(\n",
        "                          self.tgt_tok_emb(tgt)), memory,\n",
        "                          tgt_mask)"
      ],
      "metadata": {
        "id": "IDUjrXIMSV35"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "def create_mask(src, tgt):\n",
        "    src_seq_len = src.shape[0]\n",
        "    tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len), device=device).type(torch.bool)\n",
        "\n",
        "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
        "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
      ],
      "metadata": {
        "id": "CdQY4ugaTMvj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "Q0hWsTCdgRbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "NUM_EPOCHS = 13\n",
        "\n",
        "transformer = Seq2SeqTransformer(\n",
        "    num_encoder_layers = 3, \n",
        "    num_decoder_layers = 3,\n",
        "    emb_size = 512, \n",
        "    src_vocab_size = len(de_vocab), \n",
        "    tgt_vocab_size = len(en_vocab),\n",
        "    dim_feedforward = 512\n",
        "    ) \n",
        "\n",
        "for p in transformer.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "transformer = transformer.to(device)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9\n",
        ")"
      ],
      "metadata": {
        "id": "WVVEB430TkeH"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and eval functions\n",
        "\n",
        "We define the training step excluding the source mask so that the encoder applies full attention to the source sentence. We do pass a target mask to avoid attending to future tokens in the training target sentence."
      ],
      "metadata": {
        "id": "cmD9NhQtgUNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, train_iter, optimizer):\n",
        "  model.train()\n",
        "  losses = 0\n",
        "  for idx, (src, tgt) in enumerate(train_iter):\n",
        "      src = src.to(device)\n",
        "      tgt = tgt.to(device)\n",
        "\n",
        "      tgt_input = tgt[:-1, :]\n",
        "      _, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "      logits = model(src,\n",
        "                     tgt_input, \n",
        "                     None, # source mask\n",
        "                     tgt_mask,\n",
        "                     src_padding_mask, \n",
        "                     tgt_padding_mask, \n",
        "                     src_padding_mask)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      tgt_out = tgt[1:,:]\n",
        "      loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "      losses += loss.item()\n",
        "  return losses / len(train_iter)\n",
        "\n",
        "def evaluate(model, val_iter):\n",
        "    model.eval()\n",
        "    losses = 0\n",
        "    for idx, (src, tgt) in (enumerate(valid_iter)):\n",
        "        src = src.to(device)\n",
        "        tgt = tgt.to(device)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        _, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        logits = model(src, \n",
        "                       tgt_input, \n",
        "                       None, # source mask\n",
        "                       tgt_mask,\n",
        "                       src_padding_mask, \n",
        "                       tgt_padding_mask, \n",
        "                       src_padding_mask)\n",
        "        tgt_out = tgt[1:,:]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        losses += loss.item()\n",
        "    return losses / len(val_iter)"
      ],
      "metadata": {
        "id": "RISCGONmUMi8"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training loop"
      ],
      "metadata": {
        "id": "pLWOozlEJamC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses, val_losses = [], []\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    start_time = time.time()\n",
        "    train_loss = train_epoch(transformer, train_iter, optimizer)\n",
        "    end_time = time.time()\n",
        "    val_loss = evaluate(transformer, valid_iter)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    \n",
        "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"\n",
        "          f\"Epoch time = {(end_time - start_time):.3f}s\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n9FCaq8CC8D",
        "outputId": "2bd6d27d-8d92-48b4-f421-718694c122f0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Train loss: 5.343, Val loss: 4.091, Epoch time = 33.444s\n",
            "Epoch: 2, Train loss: 3.732, Val loss: 3.269, Epoch time = 34.083s\n",
            "Epoch: 3, Train loss: 3.129, Val loss: 2.856, Epoch time = 34.320s\n",
            "Epoch: 4, Train loss: 2.737, Val loss: 2.593, Epoch time = 34.543s\n",
            "Epoch: 5, Train loss: 2.445, Val loss: 2.415, Epoch time = 34.804s\n",
            "Epoch: 6, Train loss: 2.215, Val loss: 2.276, Epoch time = 35.327s\n",
            "Epoch: 7, Train loss: 2.023, Val loss: 2.161, Epoch time = 35.671s\n",
            "Epoch: 8, Train loss: 1.858, Val loss: 2.093, Epoch time = 35.620s\n",
            "Epoch: 9, Train loss: 1.717, Val loss: 2.023, Epoch time = 35.568s\n",
            "Epoch: 10, Train loss: 1.591, Val loss: 1.998, Epoch time = 35.684s\n",
            "Epoch: 11, Train loss: 1.482, Val loss: 1.952, Epoch time = 35.746s\n",
            "Epoch: 12, Train loss: 1.382, Val loss: 1.928, Epoch time = 35.735s\n",
            "Epoch: 13, Train loss: 1.292, Val loss: 1.895, Epoch time = 35.788s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7,7))\n",
        "plt.plot(range(len(train_losses)), train_losses,label='training' )\n",
        "plt.plot(range(len(val_losses)), val_losses,label='validation' )\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('cross entropy loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "p6DH7hYMDCbI",
        "outputId": "5e420dd1-d3bb-4b08-e161-a989d2c88cc8"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that there is some overfitting with current model + data combination."
      ],
      "metadata": {
        "id": "4OYahnhvPh3p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference\n",
        "\n",
        "We collect methods to translate and show examples."
      ],
      "metadata": {
        "id": "A21iG9xcO2SS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_decode(model, src, src_mask, max_len, start_symbol=BOS_IDX):\n",
        "    \"\"\"\n",
        "    Helper function which greedily predicts next token given previous \n",
        "    predictions.\n",
        "\n",
        "    Args:\n",
        "        model: transformer model for sequence-to-sequence translation.\n",
        "        src: input sentence to translate.\n",
        "        src_mask: source mask.\n",
        "        max_len: maximum length of predicted sentence.\n",
        "        start_symbol: starting token in predicted sentence. By default the\n",
        "            constant BOS_IDX.\n",
        "\n",
        "    Returns:\n",
        "        ys: predicted senquence of tokens.\n",
        "    \"\"\"\n",
        "    src = src.to(device)\n",
        "    \n",
        "    if src_mask is not None: src_mask = src_mask.to(device)\n",
        "\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(device)\n",
        "    for i in range(max_len-1):\n",
        "        memory = memory.to(device)\n",
        "        memory_mask = torch.zeros(ys.shape[0], memory.shape[0]).to(device).type(torch.bool)\n",
        "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
        "                                    .type(torch.bool)).to(device)\n",
        "        out = model.decode(ys, memory, tgt_mask)\n",
        "        out = out.transpose(0, 1)\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim = 1)\n",
        "        next_word = next_word.item()\n",
        "\n",
        "        ys = torch.cat(\n",
        "            [ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "        if next_word == EOS_IDX:\n",
        "          break\n",
        "    return ys\n",
        "\n",
        "\n",
        "def translate(model: Seq2SeqTransformer, \n",
        "              src: str, \n",
        "              src_vocab: Vocab, \n",
        "              tgt_vocab: Vocab, \n",
        "              src_tokenizer) -> str:\n",
        "    \"\"\"\n",
        "    Translates source sentence using transformer.\n",
        "\n",
        "    Args:\n",
        "        model: transformer model for sequence-to-sequence translation.\n",
        "        src: input sentence to translate.\n",
        "        src_vocab: source torchtext vocabulary object.\n",
        "        tgt_vocab: target torchtext vocabulary object.\n",
        "        src_tokenizer: source tokenizer.\n",
        "\n",
        "    Returns:\n",
        "        translated version of input sentence.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    tokens = [BOS_IDX] + [src_vocab.get_stoi()[tok] for tok in src_tokenizer(src)]+ [EOS_IDX]\n",
        "    num_tokens = len(tokens)\n",
        "    src = (torch.LongTensor(tokens).reshape(num_tokens, 1) )\n",
        "    # Just as during training, we do not apply a source mask, instead we \n",
        "    # pass None\n",
        "    tgt_tokens = greedy_decode(model, \n",
        "                               src, \n",
        "                               src_mask=None, \n",
        "                               max_len=num_tokens + 5, \n",
        "                               start_symbol=BOS_IDX).flatten()\n",
        "    return \" \".join(\n",
        "        [tgt_vocab.get_itos()[tok] for tok in tgt_tokens]\n",
        "        ).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
      ],
      "metadata": {
        "id": "6_o30pb0UvVO"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translate(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\", \n",
        "          de_vocab, en_vocab, de_tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OIT0NE7hLObm",
        "outputId": "92cf3766-c9d9-45c8-b114-6e5b9bc7b618"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' A group of people standing in front of an auditorium . '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translate(transformer, \"Die Autos fahren schnell\", \n",
        "          de_vocab, en_vocab, de_tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "uSO6w5VkBQ1T",
        "outputId": "af512912-22fb-46f7-c6e3-e7291a959552"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The cars are racing up . '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "W6S3rrUPLjDT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}