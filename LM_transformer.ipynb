{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LM_transformer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Language modeling using a transformer encoder\n",
        "\n",
        "We will build a model which relies on the transformer encoder for the task of language modeling. "
      ],
      "metadata": {
        "id": "F54u-quTkpvg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmVFkFSkqRhA",
        "outputId": "e2da6813-4450-4f44-e781-5053f4ca16ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchdata\n",
            "  Downloading torchdata-0.3.0-py3-none-any.whl (47 kB)\n",
            "\u001b[K     |████████████████████████████████| 47 kB 2.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchdata) (1.11.0+cu113)\n",
            "Collecting urllib3>=1.25\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchdata) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0->torchdata) (4.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata) (2.10)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 58.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: urllib3, torchdata\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed torchdata-0.3.0 urllib3-1.25.11\n"
          ]
        }
      ],
      "source": [
        "!pip install torchdata\n",
        "import math\n",
        "import copy\n",
        "import time\n",
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "import torch.nn.functional as F \n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer \n",
        "from torch.utils.data import dataset\n",
        "\n",
        "import torchtext\n",
        "from torchtext.datasets import WikiText2\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer (encoder) model\n",
        "Structure of the `TransformerModel`:\n",
        "\n",
        "* A source equence of tokens are passed to the embedding layer first, \n",
        "* followed by a positional encoding layer to account for the order of the words,\n",
        "* both the positionally-encoded source sequence and a corresponding a square source mask is passed to the transformer encoder.\n",
        "\n",
        "Along with the source sequence, a square attention mask is required because the self-attention layers in `nn.TransformerEncoder` are only allowed to attend the earlier positions in the sequence. For the language modeling task, any tokens on the future positions should be masked."
      ],
      "metadata": {
        "id": "tQ75qAZhcUtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Computes positional encoding.\n",
        "\n",
        "    Args:\n",
        "        d_model: embedding dimension. The positional encodings have the same \n",
        "            dimension as the embeddings so that the two can be summed\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
        "        \"\"\"\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)\n",
        "\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Transformer encoder model for language modeling. The language modeling task \n",
        "    is to assign a probability for the likelihood of a given word \n",
        "    (or a sequence of words) to follow a sequence of words.\n",
        "\n",
        "    Args:\n",
        "        ntoken: vocabulary size (number of tokens).\n",
        "        d_model: embedding dimension.\n",
        "        nhead:  the number of heads in the multiheadattention models.\n",
        "        d_hid: dimension of the feedforward network model in the encoder \n",
        "            layers (nn.TransformerEncoderLayer).\n",
        "        nlayers: number of encoder layers in the encoder (nn.TransformerEncoder).\n",
        "    \"\"\"\n",
        "    def __init__(self, \n",
        "                 ntoken: int, \n",
        "                 d_model: int, \n",
        "                 nhead: int, \n",
        "                 d_hid: int,\n",
        "                 nlayers: int, \n",
        "                 dropout: float = 0.1\n",
        "    ) -> None:\n",
        "\n",
        "        super().__init__()\n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "        self.encoder = nn.Embedding(ntoken, d_model)\n",
        "        self.d_model = d_model\n",
        "        self.decoder = nn.Linear(d_model, ntoken)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self) -> None:\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src: Tensor, src_mask: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            src: Tensor, shape [seq_len, batch_size]\n",
        "            src_mask: Tensor, shape [seq_len, seq_len]\n",
        "\n",
        "        Returns:\n",
        "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
        "        \"\"\"\n",
        "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, src_mask) # size = [seq_len, batch_size, d_model]\n",
        "        output = self.decoder(output) # size = [seq_len, batch_size, ntoken]\n",
        "        return output\n",
        "\n",
        "\n",
        "def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
        "    \"\"\"Generates an upper-triangular matrix of -inf, with zeros on diag.\"\"\"\n",
        "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)"
      ],
      "metadata": {
        "id": "RfQD1ABVzyv0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data processing"
      ],
      "metadata": {
        "id": "uSGTwOdz7LuC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Build vocabulary using `torchtext.vocab.Vocab` object"
      ],
      "metadata": {
        "id": "b3cPoBuIilCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build vocab\n",
        "train_iter = WikiText2(split='train')\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
        "vocab.set_default_index(vocab['<unk>'])"
      ],
      "metadata": {
        "id": "zhOA6V3T6fyp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def data_process(raw_text_iter: dataset.IterableDataset) -> Tensor:\n",
        "    \"\"\"Converts raw text into a flat Tensor.\"\"\"\n",
        "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n",
        "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
        "\n",
        "def batchify(data: Tensor, bsz: int) -> Tensor:\n",
        "    \"\"\"Divides the data into bsz separate sequences, removing extra elements\n",
        "    that wouldn't cleanly fit.\n",
        "\n",
        "    Args:\n",
        "        data: Tensor, shape [N]\n",
        "        bsz: int, batch size\n",
        "\n",
        "    Returns:\n",
        "        Tensor of shape [N // bsz, bsz]\n",
        "    \"\"\"\n",
        "    seq_len = data.size(0) // bsz\n",
        "    # cut off those elemements which don't fit in a batch\n",
        "    data = data[:seq_len * bsz]\n",
        "    data = data.view(bsz, seq_len).t().contiguous()\n",
        "    return data.to(device)\n",
        "\n",
        "# get train, validation, and test data\n",
        "train_iter, val_iter, test_iter = WikiText2()\n",
        "train_data = data_process(train_iter)\n",
        "val_data = data_process(val_iter)\n",
        "test_data = data_process(test_iter)\n",
        "\n",
        "# build dataloaders\n",
        "batch_size = 20\n",
        "eval_batch_size = 10\n",
        "train_data = batchify(train_data, batch_size)  # shape [seq_len, batch_size]\n",
        "val_data = batchify(val_data, eval_batch_size)\n",
        "test_data = batchify(test_data, eval_batch_size)"
      ],
      "metadata": {
        "id": "gJh3X7NW6iob"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training and evaluating functions"
      ],
      "metadata": {
        "id": "qLp7Z77AjGrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model \n",
        "ntokens = len(vocab)  # size of vocabulary\n",
        "emsize = 200  # embedding dimension\n",
        "d_hid = 200  # dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 2  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # number of heads in nn.MultiheadAttention\n",
        "dropout = 0.2  # dropout probability\n",
        "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 5.0  # learning rate\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)"
      ],
      "metadata": {
        "id": "9tIzDUQZXpwP"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BPTT = 35 # max \"backprop through time\", i.e. sequence length\n",
        "\n",
        "def get_batch(source: Tensor, i: int) -> Tuple[Tensor, Tensor]:\n",
        "    \"\"\"\n",
        "    Gets batch with max sequence length BPTT.\n",
        "\n",
        "    Args:\n",
        "        source: Tensor, shape [full_seq_len, batch_size]\n",
        "        i: index of batch to return\n",
        "\n",
        "    Returns:\n",
        "        tuple (data, target), where data has shape [seq_len, batch_size] and\n",
        "        target has shape [seq_len * batch_size]\n",
        "    \"\"\"\n",
        "    seq_len = min(BPTT, len(source) - 1 - i)\n",
        "    data = source[i:i+seq_len]\n",
        "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
        "    return data, target\n",
        "\n",
        "def train(model: nn.Module) -> None:\n",
        "    model.train()  # turn on train mode\n",
        "    total_loss = 0.\n",
        "    log_interval = 200\n",
        "    start_time = time.time()\n",
        "    src_mask = generate_square_subsequent_mask(BPTT).to(device)\n",
        "\n",
        "    num_batches = len(train_data) // BPTT\n",
        "    for batch, i in enumerate(range(0, train_data.size(0) - 1, BPTT)):\n",
        "        data, targets = get_batch(train_data, i)\n",
        "        batch_size = data.size(0)\n",
        "        if batch_size != BPTT:  # only on last batch\n",
        "            src_mask = src_mask[:batch_size, :batch_size]\n",
        "        output = model(data, src_mask)\n",
        "        loss = criterion(output.view(-1, ntokens), targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if batch % log_interval == 0 and batch > 0:\n",
        "            lr = scheduler.get_last_lr()[0]\n",
        "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
        "            cur_loss = total_loss / log_interval\n",
        "            ppl = math.exp(cur_loss)\n",
        "            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
        "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
        "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def evaluate(model: TransformerModel, eval_data: Tensor) -> float:\n",
        "    \"\"\"\n",
        "    Evaluates given transformer encoder model on eval_data.\n",
        "    \"\"\"\n",
        "    model.eval()  # turn on evaluation mode\n",
        "    total_loss = 0.\n",
        "    src_mask = generate_square_subsequent_mask(BPTT).to(device)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, eval_data.size(0) - 1, BPTT):\n",
        "            data, targets = get_batch(eval_data, i)\n",
        "            batch_size = data.size(0)\n",
        "            if batch_size != BPTT:\n",
        "                src_mask = src_mask[:batch_size, :batch_size]\n",
        "            output = model(data, src_mask)\n",
        "            output_flat = output.view(-1, ntokens)\n",
        "            total_loss += batch_size * criterion(output_flat, targets).item()\n",
        "    return total_loss / (len(eval_data) - 1)"
      ],
      "metadata": {
        "id": "MwO713W8QP_y"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Example of outputs of some of the functions above:"
      ],
      "metadata": {
        "id": "YK4KBsWGl8NQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data = ['today is sunny', \n",
        "               'my car works', \n",
        "               'trees are green', \n",
        "               'book worms fall', \n",
        "               'moon chair show',\n",
        "               'plane boat bone']\n",
        "\n",
        "# map sample_data to flat tensor of indeces\n",
        "idx_data = data_process(sample_data)\n",
        "idx_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YM6DXGYQmC0c",
        "outputId": "532528df-1f41-4b71-85fd-859bc6bff16e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  802,    23, 13787,   447,  1380,   499,  1101,    34,  1213,   244,\n",
              "        11441,  1343,  2374,  4923,   247,  3502,  1681,  3242])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Map indexed data to 4 batches. Note that batch dim is the second one.\n",
        "batched_data = batchify(idx_data, bsz = 4)\n",
        "batched_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZKmBHymmUGP",
        "outputId": "3b9e94e2-363b-41ef-f37e-1b30c855ba72"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  802,  1380,  1213,  2374],\n",
              "        [   23,   499,   244,  4923],\n",
              "        [13787,  1101, 11441,   247],\n",
              "        [  447,    34,  1343,  3502]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the first batch\n",
        "data, target = get_batch(batched_data, 0)\n",
        "print('data', data)\n",
        "print('target', target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtVatXC7mnjP",
        "outputId": "6ed40efe-5629-4fbf-d9a4-1dfa23446936"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data tensor([[  802,  1380,  1213,  2374],\n",
            "        [   23,   499,   244,  4923],\n",
            "        [13787,  1101, 11441,   247]], device='cuda:0')\n",
            "target tensor([   23,   499,   244,  4923, 13787,  1101, 11441,   247,   447,    34,\n",
            "         1343,  3502], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Easier to read target when not flattened. Note target is obtained by shifting\n",
        "# by one element the sequence in batched_data with respect to data, as well as\n",
        "# looking one element into the future.\n",
        "target.view(-1, 4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF73TiRxnGUX",
        "outputId": "63ca4a86-e978-4078-a99c-77a85d82ad6b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   23,   499,   244,  4923],\n",
              "        [13787,  1101, 11441,   247],\n",
              "        [  447,    34,  1343,  3502]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training loop"
      ],
      "metadata": {
        "id": "YOX4PUTojMtn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "best_val_loss = float('inf')\n",
        "epochs = 3\n",
        "# to store best model\n",
        "best_model = None\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(model)\n",
        "    val_loss = evaluate(model, val_data)\n",
        "    val_ppl = math.exp(val_loss)\n",
        "    elapsed = time.time() - epoch_start_time\n",
        "    print('-' * 89)\n",
        "    print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
        "          f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
        "    print('-' * 89)\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_model = copy.deepcopy(model)\n",
        "\n",
        "    scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-485cV2KPntC",
        "outputId": "82b0e5b9-4dbc-417f-d4d7-fc5ec57c4030"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   200/ 2928 batches | lr 5.00 | ms/batch 15.79 | loss  8.07 | ppl  3211.27\n",
            "| epoch   1 |   400/ 2928 batches | lr 5.00 | ms/batch 15.44 | loss  6.85 | ppl   942.32\n",
            "| epoch   1 |   600/ 2928 batches | lr 5.00 | ms/batch 15.46 | loss  6.44 | ppl   624.99\n",
            "| epoch   1 |   800/ 2928 batches | lr 5.00 | ms/batch 15.53 | loss  6.30 | ppl   542.15\n",
            "| epoch   1 |  1000/ 2928 batches | lr 5.00 | ms/batch 15.58 | loss  6.19 | ppl   490.21\n",
            "| epoch   1 |  1200/ 2928 batches | lr 5.00 | ms/batch 15.62 | loss  6.16 | ppl   473.61\n",
            "| epoch   1 |  1400/ 2928 batches | lr 5.00 | ms/batch 15.64 | loss  6.12 | ppl   453.82\n",
            "| epoch   1 |  1600/ 2928 batches | lr 5.00 | ms/batch 15.69 | loss  6.11 | ppl   451.28\n",
            "| epoch   1 |  1800/ 2928 batches | lr 5.00 | ms/batch 15.70 | loss  6.03 | ppl   414.16\n",
            "| epoch   1 |  2000/ 2928 batches | lr 5.00 | ms/batch 15.73 | loss  6.02 | ppl   409.76\n",
            "| epoch   1 |  2200/ 2928 batches | lr 5.00 | ms/batch 15.69 | loss  5.90 | ppl   363.49\n",
            "| epoch   1 |  2400/ 2928 batches | lr 5.00 | ms/batch 15.66 | loss  5.97 | ppl   390.57\n",
            "| epoch   1 |  2600/ 2928 batches | lr 5.00 | ms/batch 15.60 | loss  5.96 | ppl   386.13\n",
            "| epoch   1 |  2800/ 2928 batches | lr 5.00 | ms/batch 15.73 | loss  5.88 | ppl   358.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 47.84s | valid loss  5.82 | valid ppl   337.66\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   2 |   200/ 2928 batches | lr 4.75 | ms/batch 15.56 | loss  5.86 | ppl   351.67\n",
            "| epoch   2 |   400/ 2928 batches | lr 4.75 | ms/batch 15.47 | loss  5.85 | ppl   347.24\n",
            "| epoch   2 |   600/ 2928 batches | lr 4.75 | ms/batch 15.39 | loss  5.66 | ppl   288.51\n",
            "| epoch   2 |   800/ 2928 batches | lr 4.75 | ms/batch 15.38 | loss  5.71 | ppl   301.12\n",
            "| epoch   2 |  1000/ 2928 batches | lr 4.75 | ms/batch 15.37 | loss  5.66 | ppl   287.62\n",
            "| epoch   2 |  1200/ 2928 batches | lr 4.75 | ms/batch 15.34 | loss  5.69 | ppl   295.19\n",
            "| epoch   2 |  1400/ 2928 batches | lr 4.75 | ms/batch 15.36 | loss  5.70 | ppl   297.46\n",
            "| epoch   2 |  1600/ 2928 batches | lr 4.75 | ms/batch 15.35 | loss  5.71 | ppl   301.75\n",
            "| epoch   2 |  1800/ 2928 batches | lr 4.75 | ms/batch 15.35 | loss  5.66 | ppl   287.00\n",
            "| epoch   2 |  2000/ 2928 batches | lr 4.75 | ms/batch 15.35 | loss  5.67 | ppl   290.24\n",
            "| epoch   2 |  2200/ 2928 batches | lr 4.75 | ms/batch 15.35 | loss  5.55 | ppl   257.93\n",
            "| epoch   2 |  2400/ 2928 batches | lr 4.75 | ms/batch 15.44 | loss  5.65 | ppl   284.47\n",
            "| epoch   2 |  2600/ 2928 batches | lr 4.75 | ms/batch 15.40 | loss  5.65 | ppl   283.85\n",
            "| epoch   2 |  2800/ 2928 batches | lr 4.75 | ms/batch 15.42 | loss  5.58 | ppl   265.33\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 47.16s | valid loss  5.65 | valid ppl   285.42\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   3 |   200/ 2928 batches | lr 4.51 | ms/batch 15.53 | loss  5.60 | ppl   271.71\n",
            "| epoch   3 |   400/ 2928 batches | lr 4.51 | ms/batch 15.52 | loss  5.63 | ppl   277.37\n",
            "| epoch   3 |   600/ 2928 batches | lr 4.51 | ms/batch 15.69 | loss  5.43 | ppl   228.83\n",
            "| epoch   3 |   800/ 2928 batches | lr 4.51 | ms/batch 15.55 | loss  5.49 | ppl   242.35\n",
            "| epoch   3 |  1000/ 2928 batches | lr 4.51 | ms/batch 15.54 | loss  5.44 | ppl   230.26\n",
            "| epoch   3 |  1200/ 2928 batches | lr 4.51 | ms/batch 15.54 | loss  5.48 | ppl   240.12\n",
            "| epoch   3 |  1400/ 2928 batches | lr 4.51 | ms/batch 15.51 | loss  5.50 | ppl   244.69\n",
            "| epoch   3 |  1600/ 2928 batches | lr 4.51 | ms/batch 15.49 | loss  5.53 | ppl   251.58\n",
            "| epoch   3 |  1800/ 2928 batches | lr 4.51 | ms/batch 15.54 | loss  5.48 | ppl   239.88\n",
            "| epoch   3 |  2000/ 2928 batches | lr 4.51 | ms/batch 15.52 | loss  5.49 | ppl   242.11\n",
            "| epoch   3 |  2200/ 2928 batches | lr 4.51 | ms/batch 15.48 | loss  5.37 | ppl   213.87\n",
            "| epoch   3 |  2400/ 2928 batches | lr 4.51 | ms/batch 15.48 | loss  5.46 | ppl   235.96\n",
            "| epoch   3 |  2600/ 2928 batches | lr 4.51 | ms/batch 15.47 | loss  5.48 | ppl   238.90\n",
            "| epoch   3 |  2800/ 2928 batches | lr 4.51 | ms/batch 15.41 | loss  5.41 | ppl   223.36\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 47.51s | valid loss  5.60 | valid ppl   269.61\n",
            "-----------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eval on hold-out test set"
      ],
      "metadata": {
        "id": "_4ch5mHcoGKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = evaluate(best_model, test_data)\n",
        "test_ppl = math.exp(test_loss)\n",
        "print(f'| After training:  test loss {test_loss:5.2f} | '\n",
        "      f'test ppl {test_ppl:8.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfzsyAPRP8Fg",
        "outputId": "85d62f31-d80f-4654-b781-773b43853ada"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| After training:  test loss  5.51 | test ppl   246.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "YGzwAiTvjrlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def infer(text: str, \n",
        "          model: TransformerModel, \n",
        "          vocab_object: torchtext.vocab.Vocab,\n",
        "          num_pred: int = 1,):\n",
        "    \"\"\"\n",
        "    Method to predict num = i words following an input sequence.\n",
        "\n",
        "    Args:\n",
        "        text: string to use as input sequence.\n",
        "        model: trained transformer model.\n",
        "        num_pred: number of tokens to predict.\n",
        "    \"\"\"\n",
        "    # extend by one token so we don't lose the original last token when \n",
        "    # calling get_batch\n",
        "    dummy_iter = [text + ' <unk>']\n",
        "    idx_data = data_process(dummy_iter)\n",
        "    # put whole thing into batch\n",
        "    batched_data = batchify(idx_data, 1)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        data, _ = get_batch(batched_data, 0)\n",
        "        while num_pred > 0:\n",
        "            src_mask = generate_square_subsequent_mask(data.size(0)).to(device)\n",
        "            output = model(data, src_mask) # size = [seq_len, batch size, vocab size]\n",
        "            # use last prediction in the sequence\n",
        "            output = output[-1:]\n",
        "            # choose highest logit\n",
        "            pred_idx = output.argmax(axis=-1) # size = [1, batch size]\n",
        "            # append prediction to input sequence\n",
        "            new_seq = torch.concat((data, pred_idx) , dim=0)\n",
        "            data = new_seq\n",
        "            num_pred -= 1\n",
        "\n",
        "            new_seq = data\n",
        "\n",
        "        new_text = ' '.join(vocab_object.lookup_tokens(new_seq.squeeze().tolist()))\n",
        "        return new_text"
      ],
      "metadata": {
        "id": "7Osj9edJh1SG"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some inference examples using random input phrases. We will predict the following three words."
      ],
      "metadata": {
        "id": "aa9hOYUzfoy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"the construction of ships offered ice\"\n",
        "infer(s, best_model, vocab, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JyF9Q5E9Ydz7",
        "outputId": "49082385-faf8-4acd-9c9a-0ad551072cb5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the construction of ships offered ice age of the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"our fathers have eaten\"\n",
        "infer(s, best_model, vocab, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "v9uJyLhhZJs5",
        "outputId": "b6683290-983d-413f-8c10-ba7a7bd74ab8"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'our fathers have eaten in the first'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"the engine inside\"\n",
        "infer(s, best_model, vocab, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "23gTG6freM25",
        "outputId": "4f43372e-039a-4456-f10a-327c471eabe0"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the engine inside the first quarter'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"Those tall trees gave us\"\n",
        "infer(s, best_model, vocab, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IcHtbd2qeW6F",
        "outputId": "144a2112-f031-4365-ad25-9a3faf54e928"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'those tall trees gave us $ 1 million'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"The men were highly\"\n",
        "infer(s, best_model, vocab, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Lkl9nrx9euuz",
        "outputId": "d506edb3-8cbb-4260-8eda-85821756a4dd"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the men were highly successful in the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"We ate\"\n",
        "infer(s, best_model, vocab, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5ykrxQpufSFC",
        "outputId": "a25b2fbf-0b13-4a64-b334-02940b0d93ce"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'we ate . . .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://towardsdatascience.com/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1"
      ],
      "metadata": {
        "id": "R-3V9IFxbYsL"
      }
    }
  ]
}